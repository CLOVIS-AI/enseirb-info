\documentclass[a4paper,10pt,french,openany]{memoir}
\usepackage[utf8]{inputenc}
\usepackage{babel}

\usepackage{clovisai}
\newcommand{\Proba}{\mathbb{P}}
\newcommand{\Esper}{\mathbb{E}}
\newcommand{\Var}{Var}
\newcommand{\tribu}[1]{\mathcal{#1}}
\newcommand{\implique}{\Rightarrow}
\newcommand{\abs}[1]{\lvert #1 \rvert}
\newcommand{\laweq}{\overset{\mathcal L}=}
\newcommand{\xonen}{x_1\dots x_n}
\newcommand{\Xonen}{X_1\dots X_n}
\newcommand{\xoned}{x_1\dots x_d}
\newcommand{\Xoned}{X_1\dots X_d}
\newcommand{\xonek}{x_1\dots x_k}
\DeclareMathOperator{\jac}{Jac}

%opening
\title{Probabilités et Statistiques}
\author{François Dufour (\hrefu{mailto://francois.dufour@math.u-bordeaux.fr}{francois.dufour@math.u-bordeaux.fr})\\Notes prises par Ivan Canet}

\begin{document}

\maketitle
\tableofcontents

\chapter{Probabilités sur un espace fini}
\section{Probabilités sur un espace fini, événements}
\subsection{Définitions}

\paragraph{Notation}
On s'intéresse à l'expérience \emph{aléatoire} qui conduit à la réalisation d'un seul résultat parmi un nombre \emph{fini} de résultats possibles, notés $\omega_1\dots \omega_n$. On note $\Omega = \lbrace \omega_1\dots\omega_n \rbrace$ l'ensemble de ces résultats.\\
Par exemple, un jeu de pile ou face peut être modélisé en $\Omega = \lbrace P, F \rbrace$.

\paragraph{Probabilité}
Une probabilité $\Proba$ sur l'ensemble $\Omega = \lbrace \omega_1\dots\omega_n \rbrace$ est une \emph{pondération} de $p_1\dots p_n$ où $n$ est un nombre réel positif, tels que:
\[\sum_{i=1}^n p_i = 1\]

\paragraph{Événement}
On appelle événement tout sous-ensemble de $\Omega$.

Pour un événement $A \subset \Omega$, on définit:
\[\Proba(A) = \sum_{i=1}^n p_i\]
où $\Proba(A)$ est appelé la \emph{probabilité de $A$}.

\paragraph{Terminologie}
\begin{itemize}
 \item Si $\Proba(A)=0$, l'événement est dit \emph{négligeable}.
 \item Si $\Proba(A)=1$, l'événement est dit \emph{presque sûr}.
 \item Le contraire de $A$ est $\bar{A}$.
 \item L'événement «~$A$ et $B$~»: $A \inter B$
 \item L'évenement «~$A$ ou $B$~»: $A \union B$
\end{itemize}

On peut démontrer que:
\[ \Proba(A \union B) = \Proba(A) + \Proba(B) - \Proba(A \inter B) \]
\[ \Proba(A \inter B) = \Proba(A) + \Proba(B) - \Proba(A \union B) \]

\paragraph{Fonction indicatrice} La fonction indicatrice d'un événement $A$ est définie comme
$ I_A: \Omega \rightarrow \lbrace 0, 1 \rbrace $
telle que:
\[
\forall u \in \Omega, \; I_A(\omega) = \begin{cases*}
1 & si $\omega \in A$ \\ 
0 & si $\omega \notin A$
\end{cases*}
\]

On retrouve aussi
\[I_{A \inter B} = I_A I_B\]
\[I_{A \union B} = I_A + I_B - I_{A \inter B}\]

\subsection{Exemple}

La probabilité uniforme fait que tous les événements élémentaires $\omega_1\dots\omega_n$ vont avoir la même probabilité.

\[ p_i = p_1, \; \forall i \in \lbrace 1 \dots n \rbrace \]

\[ 1 = \sum_{i=1}^n p_i = n p_1 = card(\Omega) p_1 \]
donc $p_i = \frac{1}{card(\Omega)}$, et
\[ \Proba(A) = \sum_{\omega_i \in A} p_i = \frac{card(A)}{card(B)} \]

\section{Probabilités conditionnelles et indépendance}
\subsection{Probabilité conditionnelle}

La probabilité conditionnelle permet de prendre en compte l'information dont on dispose pour actualiser la probabilité d'un événement.

\paragraph{Définition}
Soit $\Omega$ un ensemble muni d'une probabilité $\Proba$. On considère deux événements $A$ et $B$. La probabilité conditionnelle de $A$ sachant $B$ est définie telle que:
\[
\Proba(A \sachant B) =
    \begin{cases*}
        \frac{\Proba(A \inter B)}{\Proba(B)} & si $\Proba(B) > 0$ \\
        \Proba(A) & sinon
    \end{cases*}
\]

\paragraph{Exemple 1}
Quelle est la probabilité qu'un individu ayant deux enfants ai un garçon, sachant qu'il a une fille?

$\Omega = \lbrace (F,F), (G,G), (F,G), (G,F) \rbrace$

On définit $A$ l'événement \emph{avoir un garçon} et $B$ l'événement \emph{avoir une fille}.

\[ \Proba(A \sachant B) = \frac{\Proba(A \inter B)}{\Proba(B)} = \frac{card(A \inter B)}{card(B)} = \frac{2}{3} \]
donc, la probabilité que l'individu ai un garçon, en sachant qu'il a une fille, est $\frac 2 3$.

\paragraph{Exemple 2}
Quelle est la probabilité qu'un individu ayant deux enfants ai un garçon, sachant que l'aînée est une fille?

$\Omega = \lbrace (F,F), (G,G), (G,F) \rbrace$ \textit{(on ignore l'ordre)}

\[ \Proba(F,F)=\Proba(G,G)=\frac 1 4 \]
\[ \Proba(F,G)=\frac 1 2 \]
donc, la probabilité que l'individu ai un garçon, en sachant que l'aînée est une fille, est $\frac 1 2$.

\paragraph{Remarque}
$\Proba(A \inter B) = \Proba(A \sachant B) \Proba(B)$

\paragraph{Formule de Bayes}
Soit $B_1 \dots B_n$ une partition de $\Omega$ ($B_i \inter B_j = \emptyset$ pour $i \neq j$ et $\bigcup_{i=1} B_i = \Omega$) et $A \subset \Omega$ ($\Proba(A) > 0$).

\[
\Proba(B_i \sachant A) = \frac{\Proba(A \sachant B_i) \Proba(B_i)}{\sum_{j=1}^n \Proba(A \sachant B_j) \Proba(B_j)} = \frac{\Proba(A \inter B_i)}{\sum_{j=1}^n \Proba(A \inter B_j)}
\]

\subsection{Indépendance}

\paragraph{Définition}
Soit $\Omega$ muni d'une probabilité $\Proba$, $A$ et $B$ sont des événements indépendants si et seulement si:
\[\Proba(A \inter B) = \Proba(A) \Proba(B)\]
\[\Proba(A \sachant B) = \Proba(A)\]
\[\Proba(B \sachant A) = \Proba(B)\]

$A_1 \dots A_n$ sont indépendants si et seulement si:
\[\forall j \subset \lbrace 1 \dots n \rbrace, \; \Proba(\Inter_{j \in J} A_j) = \prod_{j \in J} \Proba(A_j)\]

\chapter{Variables aléatoires discrètes}

\section{Espace de probabilité}

\paragraph{Définition}
Une tribu $\tribu{A}$ sur $\Omega$ est une famille de sous-ensembles d'$\Omega$ qui vérifie les propriétés suivantes:

\begin{itemize}
 \item $\emptyset$ et $\Omega$ sont des éléments de $\tribu A$.
 \item $A \in \tribu A \implique \bar A \in \tribu A $
 \item Si $(A_i)_{i \in \setN} \subset \tribu A \implique \Union_{i=1}^{+\infty} A_i \in \tribu A$
\end{itemize}

\paragraph{Exemples}
\begin{itemize}
 \item $\{\emptyset, \Omega\}$ est une tribu,
 \item $P(\Omega)$ est l'ensemble des parties de $\Omega$, c'est une tribu,
 \item $A \in \Omega$, $\{ A, \bar A, \emptyset, \Omega \}$ est une tribu.
\end{itemize}

\paragraph{Définition}
Soit $\Omega$ muni d'une tribu notée $\tribu A$.
On appelle probabilité sur $(\Omega, \tribu A)$ une application 
\( \Proba: \tribu A \rightarrow [0, 1] \)
qui vérifie:
\begin{itemize}
 \item $\Proba(\Omega) = 1$
 \item Si $(A_i)_{i \in I}$ est une famille dénombrable d'éléments de $\tribu A$ \emph{deux à deux disjoints} ($A_i \inter A_j = \emptyset$ pour $i \neq j$), alors:
 \[ \Proba(\Union_{i\in I} A_i) = \sum_{i\in I} \Proba(A_i) \]
\end{itemize}

Tout ce qui a été introduit au chapitre précédent reste vrai:

\[ \Proba(A \union B) = \Proba(A) + \Proba(B) - \Proba(A \inter B) \]

\[ \text{Si } \Proba(B) > 0 \text{ alors } \Proba(A \sachant B) = \frac{\Proba(A \inter B)}{\Proba(B)} \]

\paragraph{Indépendance}
Une famille quelconque d'événements est dite indépendante si toute sous-famille \emph{finie} est indépendante.

\section{Variables aléatoires discrètes}

\subsection{Définition}
On appelle variable aléatoire discrète $X$ une application $X: \Omega \rightarrow F$ où $F$ est un ensemble fini ou dénombrable. Pour $x \in F$ on note:
\[ \{X=x\} = \{\omega \in \Omega: X(\omega) \in F\} \]

Une famille du nombre $\Proba(X=x)_{x \in F}$ s'appelle la loi de $X$.

Si $A \in \Omega$ alors la fonction indicatrice $I_A$ de $A$ est une variable aléatoire et $\Proba(I_A = 1) = \Proba(A)$.

\[I_A : \Omega \rightarrow \{0,1\}\]

\begin{align*}
 \{I_A=1\} &= \{\omega \in \Omega: I_A(\omega)=1\}\\
           &= A
\end{align*}

\subsection{Indépendance des variables aléatoires}

\paragraph{Définition}
Deux variables aléatoires discrètes $X$ et $Y$ à valeurs dans $F$ et $G$ respectivement sont dites indépendantes si:
\[ \Proba(X=x, Y=y)=\Proba(X=X) \Proba(Y=y) \]
où $x\in F$ et $y \in G$. On note:
\[ \{X=x, Y=y\}=\{X=x\}\inter\{Y=y\} \]

\paragraph{Définition}
$n$ variables aléatoires $X_1\dots X_n$ à valeurs dans $F_1\dots F_n$ respectivement sont indépendantes si toute sous-famille \emph{finie} est indépendante.

\subsection{Lois discrètes usuelles}

Ce sont des variables aléatoires à valeur dans $F \subset \setN$.

\paragraph{Loi de Bernouilli} de paramètre $p \in [0,1]$.

C'est le jeu de pile ou face. On considère $X: \Omega \rightarrow \{0,1\}$:
\[ \Proba(X=1)=p \qquad\qquad \Proba(X=0)=1-p \]

L'événement $\{X=1\}$ représente un succès, et sa probabilité est associée à $p$.

\paragraph{Loi géométrique} de paramètre $p \in ]0,1]$.

$X:\Omega \rightarrow \setN$ suit une loi géométrique si:
\[ \Proba(X=k)=(1-p)^{k-1}p \]
où $k \in \setNs$.

$X$ représente le temps du premier succès dans la répétition indépendante et identiquement distribuée d'un jeu dont la probabilité de succès vaut $p$.

On considère une suite dee variables aléatoires qui sont modélisées par le jeu.

Autrement, on considère des variables aléatoires $\{Y_i\}_{i\in \setNs}$ indépendantes, et $Y_i$ suit une loi dee Bernouilli de paramètre $p\in ]0,1]$.
\[ \Proba(Y_i = 1) = p \qquad\qquad \Proba(Y_i=0)=1-p \]
où $i$ représente l'instant du jeu.

\paragraph{Loi binomiale} de paramètres $n\in \setNs$ et $p\in [0,1]$.

C'est la loi variable $X:\Omega \rightarrow \{0,n\}$ définie par: 
\[\Proba(X=k)=\parmi k n p^k (1-p)^{p-k}\]
où $k \in \{0,n\}$.

$X$ correspond au nombre de succès lors de la répétition indépendante de jeux dont la probabilité de succès vaut $p$.

On considère que $n$ variables aléatoires $(Y_i)_{i\in 1\dots n}$ sont indépendants si $Y_i$ suit une loi de Bernouilli de paramètre $p$.

\paragraph{Loi de poisson} de paramètre $\lambda \in \setRp$.

C'est la loi variable aléatoire $X: \Omega \rightarrow \setN$ définie par:
\[\Proba(X=k)=\frac{\lambda^k}{k!} e^{-\lambda}\]

Elle est utile pour compter le nombre de gens qui entrent dans un magasin, ou le nombre de voitures qui traversent une rue.

\subsection{Loi marginale}

On considère deux variables aléatoires discrètes $X$ et $Y$ à valeurs dans $F$ et $G$.
\begin{equation} \Proba(X=x)_{x\in F} \qquad\qquad \Proba(Y=y)_{y\in G} \label{eq:couple-solo}\end{equation}

$(X,Y)$ est une variable aléatoire à valeur dans $F \times G$ et est discrète, donc:
\begin{equation} \Proba((X,Y)=(x,y))_{x,y \in F \times G} \label{eq:couple-duo}\end{equation}

\paragraph{Démonstration}
\begin{align*}
 \Union_{y\in G} \{(X,Y)=(x,y)\} &= \Union_{y\in G} (\{X=x\}\inter\{Y=y\})\\
    &= \{X=x\}\inter \Omega\\
    &= \{X=x\}
\end{align*}

\begin{align*}
 \Proba(X=x) &= \Proba(\Union_{y\in G} \{X=x,Y=y\}) \\
    &= \sum_{y\in G} \Proba((X,Y)=(x,y))
\end{align*}

Si on connait la loi du couple~(\ref{eq:couple-duo}), on peut calculer chacune de ses composantes~(\ref{eq:couple-solo}). L'inverse n'est généralement vrai (ce n'est possible que si $X$ et $Y$ sont indépendants).

\section{Espérance et variance}

\subsection{Espérance}

\paragraph{Définition}
Soit $X$ une variable aléatoire discrète à valeur $F\subset \setR$. On va dire que $X$ est intégrable si:
\[\sum_{x\in F} \lvert x \rvert \Proba(X=x) < +\infty \]

Dans ce cas, l'espérance de $X$ est notée $\Esper[X]$ et vaut:
\[ \Esper[X]=\sum_{x\in F} x\, \Proba(X=x) \]

\paragraph{Cas particuliers}
L'espérance de $X$ dans le cas où $X$ suit une loi:
\begin{itemize}
 \item De Bernouilli de paramètre $p$: \[ \Esper[X]=p \]
 \item Poisson de paramètre $\lambda \in \setR$: \[\Esper[X]=\lambda\]
 \item Géométrique de paramètre $p\in ]0,1]$: \[ \Esper[X]=\frac 1 p \]
\end{itemize}

\paragraph{Propriétés}
\begin{itemize}
 \item Linéarité: Si $X$ et $Y$ sont des variables aléatoires discrètes à valeurs réelles intégrables et $\lambda \in \setR$, alors $X + \lambda Y$ est intégrable et: \[\Esper[X+\lambda Y] = \Esper[X] + \lambda\Esper[Y]\]
 \item Positivité: Si $X$ est une variable aléatoire discrète intégrable et presque sûrement positive (ie. $\Proba(X \geq 0) = 1$), alors: \[\Esper[X] \geq 0 \] \[\Esper[X] = 0 \;\Rightarrow\; \Proba(X=0)=1 \text{ et } X=0 \text{ presque sûrement}\]
 \item Si $X$ et $Y$ sont deux variables aléatoires intégrables: \[\Proba(X \leq Y) = 1 \;\Rightarrow\; \Esper[X]\leq\Esper[Y]\]
 \item Condition suffisante d'intégrabilité: Si $Y$ est une loi discrète presque sûrement positive et intégrable, $\Proba(\abs{X}\leq Y) = 1$ implique que $X$ est intégrable.
\end{itemize}

\paragraph{Théorème de transfert}
Soit $X:\Omega \rightarrow F$ une variable aléatoire discrète et $f:F \rightarrow \setR$, alors $f(x)$ est une variable discrète et intégrable et: \[\sum_{x\in F} f(x) \,\Proba(X=x) < \infty\]

Dans ce cas, \[\Esper[f(x)] = \sum_{x\in F} f(x) \,\Proba(X=x)\]

\paragraph{Remarque}
Si $f: F\rightarrow\setR$ est bornée, alors $f(x)$ est intégrable; si $\abs{F(x)} \leq M$ $\forall x \in F$, alors: \[\sum_{x\in F} \abs{F(x)} \Proba(X=x) \leq M < \infty\]

\paragraph{Exemple}
Calcul de l'espérance de la loi binomiale de paramètres $n\in\setNs$ et $p\in[0,1]$: $\Esper[X]=n p$.

\paragraph{Proposition}
Si $X$ et $Y$ sont des variables aléatoires discrètes à valeur dans $F$ et $G$ indépendantes alors pour toutes fonctions $f: F\rightarrow \setR$ et $g: G\rightarrow \setR$ avec $f(x)$ et $g(y)$ intégrables, on a que $f(x) g(y)$ est intégrable et:\[\Esper[f(x) g(y)]=\Esper[f(x)] \,\Esper[g(y)]\]

\paragraph{Proposition}
Si $X$ et $Y$ sont deux variables aléatoires discrètes à valeur dans $F$ et $G$ et vérifient \[\Esper[f(x) g(y)] = \Esper[f(x)]\,\Esper[g(y)]\] pour toutes fonctions $f:F\rightarrow \setR$ et $g: G\rightarrow \setR$ bornées, alors $X$ et $Y$ sont indépendantes.

\subsection{Variance}

\paragraph{Définition}
Soit $X:\Omega \rightarrow F$ une variable aléatoire discrète à valeurs dans $\setR$, $X$ est dite de ``carré intégrable'' si $\sum_{x\in F}x^2\, \Proba(X=x) < \infty$ et, dans ce cas, la variance vaut: \[\Var(x)=\Esper[(X-\Esper[X])^2]\]

La racine carrée de la variance s'appelle \emph{l'écart-type}, et se note: \[\sigma(x)=\sqrt{\Var(x)}\]

\paragraph{Remarques}
\begin{itemize}
 \item Si $X$ est un carré intégrable, alors $X$ est intégrable. En effet, $\abs{X}\leq\frac{1+X^2}2$ et d'après la condition suffisante d'intégrabilité, on déduit que $X$ est intégrable; d'où:
 \begin{align*}
 \Esper[X] &= \sum_{x\in F} x\,\Proba(X=x) \\
 X^2-2 \Esper[X] X+\Esper[X]^2 &= (X-\Esper[X])^2
 \end{align*}
 donc la variance a bien un sens.
 \item $\Var(X)=\Esper[X^2]-(\Esper[X])^2$
 \item $\Esper[X^2]\geq\Esper[X]^2$
\end{itemize}

\paragraph{Proposition}
Soient $X_1\dots X_n$ des variables aléatoires de carré intégrable indépendantes, alors $\sum_{i=1}^n X_i$ est de carré intégrable.

On a donc:
\[\Var \left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \Var(X_i)\]

\paragraph{Démonstration}
\begin{align*}
 \Var \left(\sum_{i=1}^n X_i\right) &= \Esper\left[\left(\sum_{i=1}^n X_i - \Esper\left[\sum_{i=1}^n X_i\right]\right)\right] \\
    &= \Esper\left[\left(\sum_{i=1}^n (X_i - \Esper[X_i])\right)\right] \\
    &= \Esper\left[\sum_{i=1}^n (X_i - \Esper[X_i]) \sum_{i=1}^n (X_j - \Esper[X_j])\right] \\
    &= \sum_{i=1}^n \sum_{j=1}^n \Esper[(X_i - \Esper[X_i])\,(X_j - \Esper[X_j])] \\
    &= \sum_{i=1}^n \Esper[(X_i - \Esper[X_i])^2] + \sum_{i=1}^n \sum_{\genfrac{}{}{0pt}{}{j=1}{i\neq j}}^n \Esper[(X_i - \Esper[X_i])(X_j - \Esper[X_j])]
\end{align*}

On pose $\varphi_i(x)$ telle que:
\[\varphi_i(x) = x - \Esper[X_i]\]
d'où:
\[\Esper[\varphi_i(X_i) \varphi_j(X_j)] = \Esper[\varphi_i(X_i)] \, \Esper[\varphi_j(X_j)] = 0\]

\chapter{Fonctions génératrices}

\paragraph{Définition}
Soit $X: \Omega \rightarrow \setN$ une variable aléatoire à valeurs entières. On appelle fonction génératrice la fonction $g_x:[-1,1]\rightarrow\setR$ telle que:
\[g_x(s)=\Esper[s^x]=\sum_{k\in \setN} s^k\,\Proba(X=k)\]

\paragraph{Proposition}
La fonction génératrice d'une variable aléatoire à valeurs entières caractérise sa loi.
\[ X \laweq Y \:\Leftrightarrow\: g_x(s)=g_y(s), \quad\forall s\in [-1,1] \]
où «~$\laweq$~» signifie ``sont de même loi''.

\paragraph{Démonstration}
On cherche à retrouver $\Proba(X=n)$ pour $n\in \setN$:
\[ \Proba(X=n)=\frac{g_x^{(n)}(0)}{n!} \]
où $g^{(n)}$ représente la dérivée $n$-ième d'une fonction.

\paragraph{Exemple}
\begin{itemize}
 \item Loi binomiale de paramètres $n\in\setNs$ et $p\in[0,1]$:
 \begin{align*}
    g_x(s) &= \sum_{k=0}^n s^k\,\Proba(X=k) \\
    &= \sum_{k=0}^n s^k\parmi{k}{n} p^k (1-p)^{n-k} \\
    &= (p s + 1 - p)^n
 \end{align*}
 \item Loi géométrique de paramètre $p\in[0,1]$:
 \begin{align*}
    g_x(s) &= \sum_{k\in\setNs} s^k p (1-p)^{k-1} \\
    &= p s \sum_{k\in\setN} (s (1-p))^k \\
    &= \frac{p s}{1 - s(1-p)}
 \end{align*}
 \item Loi de poisson de paramètre $\lambda$:
 
 \begin{align*}
    g_x(s) &= \sum_{k\in\setN} s^k \frac{\lambda^k}{k!} e^{-\lambda} \\
    &= e^{-\lambda} \sum_{k\in\setN} \frac{(\lambda s)^k}{k!} \\
    &= e^{-\lambda} e^{\lambda s} \\
    &= e^{\lambda(s-1)}
 \end{align*}
\end{itemize}

\paragraph{Proposition}
Si $X$ et $Y$ sont deux variables aléatoires à valeurs entières indpendantes:
\[g_{X+\lambda Y}(s)=g_x(s) g_y(s)\]

\paragraph{Exemple}
On considère $(X_i)_{i\geq 1}$ une suite de variables aléatoires à valeurs entières \emph{indépendantes et identiquement distribuée} (IID.) et $N$ une variable aléatoire à valeurs entières indépendante de la suite $(X_i)_{i\geq 1}$. On pose:
\[S=\begin{cases*}
X_1+X_2+\dots+X_n & si $N\neq0$ \\ 
0 & si $N=0$
\end{cases*}\]

Si $X_i$ et $N$ suivent des lois géométriques de paramètre $q$, quelle est la loi de~$S$?

\begin{align*}
 g_x(s) = \Esper\left[s^S\right] &= \sum_{k=0}^\infty s^k\,\Proba\left(\abs{S=k}\right) \\
 &= \Esper\left[s^0 I_{N=0}\right] + \Esper\left[s^{\sum_{i=1}^N X_i} I_{N>0}\right] \\
 &= \Esper\left[s^S I_{N=0}\right] + \Esper\left[s^S I_{N>0}\right] \\
 &= \Esper\left[s^S (I_{N=0} + I_{N>0})\right] \\
 &= \Esper[I_{N=0}] + \Esper\left[s^{\sum_{i=1}^N X_i} I_{N>0}\right] \\
 &= \Esper[I_N=0] + \Esper\left[s^{\sum_{i=1}^N X_i} \sum_{k=1}^\infty I_{N=k}\right] \text{ car } I_{N>0}=\sum{k=1}^\infty I_{N=k} \\
 &= \Proba(N=0) + \sum_{k=1}^\infty \Esper\left[s^{\sum_{i=1}^N X_i} I_{N=k}\right] \\
 &= \Proba(N=0) + \sum_{k=1}^\infty \Proba\left(s^{\sum_{i=1}^k X_i}\right) \Proba(N=k) \\
 &= \Proba(N=0) + \sum_{k=1}^\infty \Proba(N=k) (g_{X_i} (s))^k
\end{align*}

\chapter{Vecteurs aléatoires à densité}

\section{Définition}

On dit que le vecteur aléatoire $X = (\Xoned): \Omega \rightarrow \setR^d$ possède la densité $p: \setR^d \rightarrow \setRp$ pour tout $o$ un ouvert de $\setR^d$.

\begin{align*}
 \Proba(X\in o) &= \int_o p(x) \dif x \\
 &= \int_{\setR^d} I_0(x) p(x) \dif x \\
 &= \int_{\setR^d} I_0(\xoned) p(\xoned) \dif \xoned
\end{align*}

\paragraph{Théorème}
Le vecteur aléatoire $X:\Omega \rightarrow \setR^d$ possède la densité $p:\setR^d \rightarrow \setRp$ si et seulement si pour toute fonction bornée $f:\setR^d \rightarrow \setR$ on a que: \[\Esper[f(x)]=\int_{\setR^d}f(x)p(x) \dif x\]

\paragraph{Remarque}
Soient $X:\Omega \rightarrow \setR^d$ de densité $p$ et $f:\setR^d \rightarrow \setR$.

Si $\int_{\setR^d} \lvert f(x) \rvert p(x) \dif x < \infty$ alors $f(x)$ est dite \emph{intégrable} et:
\[ \Esper[f(x)] = \int_{\setR^d} f(x) p(x) \dif x \]

\section{Densité marginale}
Soit $X=(\Xoned):\Omega \rightarrow \setR^d$ un vecteur aléatoire à densité notée $p$, on considère $k<d$.

Le vecteur $(\Xoned)$ est-il à densité?
\[\forall o_k \text{ de }\setR^k\]
\[ \Proba((\Xoned) \in o_k) = \int_{\setR^k} I_{o_k}(\xonek) q(\xonek) \dif \xonek\]

\[\forall o_d \text{ de }\setR^d\]
\[\Proba((\Xoned) \in o_d) = \int_{\setR^d} I_{o_d}(x_1\dots x_k, x_{k+1}\dots x_d) q(\xoned) \dif \xoned\]

\paragraph{Proposition}
Soit $X$ une variable aléatoire qui possède une densité, alors tout sous-vecteur $Y$ de $X$ possède une densité marginale obtenue en intégrant la densité de $X$ sur les composantes qui ne figurent pas dans $Y$.

\section{Changement de variable}
On se pose la question suivante:
\begin{cquote}{}
 Si $X$ est une variable aléatoire qui possède une densité de valeurs dans $\setR^d$ et $f$ est la fonction $f:\setR^d \rightarrow \setR^d$, est-ce que $Y=f(x)$ est à densité?
\end{cquote}

\paragraph{Proposition}
Soit $X:\Omega \rightarrow \setR^d$ est un vecteur aléatoire qui possède la densité $p$ portée par un ouvert $o$ de $\setR^d$ (c'est-à-dire que $\int_o p(x) \dif x = 1$), et $\varphi$ une bijection de $o$ sur $G'$ de classe C', ainsi que son inverse $\varphi^{-1}$; alors $Y=f(X)$ possède la densité:
\[q(y) = I_{G'}(y)\;p(\varphi^{-1}(y)) \; \lvert \jac \varphi^{-1}(y) \rvert \]
où $\jac\varphi^{-1} (y)$ est le Jacobin de l'inverse de $\varphi$; et vaut:
\[ \jac \varphi^{-1}(y) = \det\left(\frac{\partial(\varphi^{-1}_i)}{\partial y_j}(y)\right)_{1\leq i\leq d, 1\leq j \leq d} \]

\section{Indépendance}

\paragraph{Définition}
Les vecteurs aléatoires $X_1:\Omega \rightarrow \setR^{d_1}\dots X_n:\Omega \rightarrow \setR^{d_n}$ qui possèdent les densités $p_1:\setR^{d_1}\rightarrow \setR\dots p_n:\setR^{d_n} \rightarrow \setR$, sont dites indépendantes si $X=(\Xonen)$ possède la densité $p_1(x_1) p_2(x_2) \dots p_n (x_n)$ telle que:

\begin{align*}
 X_1 &= \begin{pmatrix}X_{1,1}\\\vdots\\X_{1,d_1}\end{pmatrix} = p_1(x_1) = p_1(x_{1,n},\dots x_{1,d_1})\\
 & \vdots \\
 X_n &= \begin{pmatrix}X_{n,1}\\\vdots\\X_{n,d_n}\end{pmatrix} = p_n(x_n) = p_n(x_{n,1},\dots x_{n,d_n})
\end{align*}

\paragraph{Proposition}
Soient $X_1:\Omega \rightarrow \setR^{d_1}, \dots X_n:\Omega \rightarrow \setR^{d_n}$, $n$ variables aléatoires indépendantes, alors pour toute fonction $f_1:\setR^{d_1}\rightarrow \setR, \dots f_n:\setR^{d_n}\rightarrow \setR$ est intégrable et:
\[\Esper[f_1(X_1)\: f_2(X_2) \dots f_n(X_n)] = \Esper[f_1(X_1)]\: \Esper[f_2(X_2)] \dots \Esper[f_n(X_n)]\]

\end{document}
